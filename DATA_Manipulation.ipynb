{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA Manipulation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwjang0902/ExampleNew/blob/master/DATA_Manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "a8wavabYOjOB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MNIST 데이터 읽기 및 Ploting from tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.reset_default_graph() # 중요한 부분이다; 이것이 없으면 런타임을 항상 리셋 해 주어야 한다.\n",
        "\n",
        "\n",
        "# MNIST DATA READING\n",
        "mnist_images = input_data.read_data_sets(\"./mnist/data/\", one_hot=False)\n",
        "\n",
        "train_images,train_labels = mnist_images.train.next_batch(50000)\n",
        "valid_images,valid_labels = mnist_images.train.next_batch(10000)\n",
        "test_images, test_labels = mnist_images.test.next_batch(10000)\n",
        "\n",
        "n = 5001\n",
        "fig  =test_images[n].reshape([28,28])\n",
        "plt.imshow(fig)\n",
        "plt.title(test_labels[n])\n",
        "\n",
        "print(len(train_images),len(valid_images),len(test_images) )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0dF_kHbR1mj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MNIST 데이터 읽기 및 Ploting from Keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pylab as plt\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.reset_default_graph() # 중요한 부분이다; 이것이 없으면 런타임을 항상 리셋 해 주어야 한다.\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 #normalization(0~1)\n",
        "\n",
        "plt.imshow(x_train[0].reshape(28,28))\n",
        "plt.title(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2za_RfWKkmr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjTE1nCeTd9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pickle, gzip, numpy, urllib.request, json\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# Load the dataset\n",
        "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
        "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
        "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
        "    \n",
        "train_images, train_labels = train_set\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "\n",
        "plt.imshow(train_images[20].reshape(28,28))\n",
        "plt.title(train_labels[20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozXslgZSc4Wt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAiYyriIeCx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from array import array\n",
        " \n",
        "from struct import *\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "#파일 읽기 \n",
        "fp_image = open('train-images.idx3-ubyte','rb')\n",
        "fp_label = open('train-labels.idx1-ubyte','rb')\n",
        "\n",
        "#사용할 변수 초기화\n",
        "img = np.zeros((28,28)) #이미지가 저장될 부분\n",
        "lbl = [ [],[],[],[],[],[],[],[],[],[] ] #숫자별로 저장 (0 ~ 9)\n",
        "d = 0\n",
        "l = 0\n",
        "index=0 \n",
        " \n",
        "s = fp_image.read(16)    #read first 16byte\n",
        "l = fp_label.read(8)     #read first  8byte\n",
        "\n",
        "\n",
        "k=0                        #테스트용 index\n",
        "#read mnist and show number\n",
        "while True:    \n",
        "    s = fp_image.read(784) #784바이트씩 읽음\n",
        "    l = fp_label.read(1)   #1바이트씩 읽음\n",
        "\n",
        "    if not s:\n",
        "        break; \n",
        "    if not l:\n",
        "        break;\n",
        " \n",
        "    index = int(l[0])      \n",
        "    #print(k,\":\",index) \n",
        "\n",
        "    #unpack\n",
        "    img = np.reshape( unpack(len(s)*'B',s), (28,28)) \n",
        "    lbl[index].append(img) #각 숫자영역별로 해당이미지를 추가\n",
        "    k=k+1\n",
        " \n",
        "#print(img)\n",
        " \n",
        "plt.imshow(img,cmap = cm.binary) #binary형태의 이미지 설정\n",
        "plt.show()\n",
        " \n",
        "#print(np.shape(lbl))            #label별로 잘 지정됬는지 확인\n",
        " \n",
        "print(\"read done\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u_wBVrJ6jw_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "# 로칼에서 업로드한 파일을 읽어서 보이기\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "tf.reset_default_graph() # 중요한 부분이다; 이것이 없으면 런타임을 항상 리셋 해 주어야 한다.\n",
        "\n",
        "img = plt.imread(\"IMG_0026.JPG\")\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_fGQko56f2fD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#로칼 파일을 읽어 들이는 방법\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__4jhM5rLchB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tensorflow로 MNIST 데이터 가져오기\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "\n",
        "print(\"훈련 이미지 :\",  mnist.train.images.shape)\n",
        "print(\"훈련 라벨:\",  mnist.train.labels.shape)\n",
        "print(\"테스트 이미지 : \", mnist.test.images.shape)\n",
        "print(\"테스트 라벨 : \", mnist.test.labels.shape)\n",
        "print(\"검증 이미지 : \", mnist.validation.images.shape)\n",
        "print(\"검증 라벨 : \", mnist.validation.labels.shape)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "mnist_idx = 100\n",
        "\n",
        "\n",
        "print('[label]')\n",
        "print('one-hot vector label = ', mnist.train.labels[mnist_idx])\n",
        "print('number label = ', np.argmax(mnist.train.labels[mnist_idx]))\n",
        "print('\\n')\n",
        "\n",
        "print('[image]')\n",
        "\n",
        "for index, pixel in enumerate(mnist.train.images[mnist_idx]):\n",
        "    if index % 28 == 0:\n",
        "        print('\\n')\n",
        "    else:\n",
        "        print(\"%10f\" % pixel, end=\"\")\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "image = np.reshape(mnist.train.images[mnist_idx], [28, 28])\n",
        "plt.imshow(image, cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ukTAZTVLqYC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keras로 MNIST 데이터 가져오기\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "\n",
        "print(\"훈련 이미지 :\",  train_images.shape)\n",
        "print(\"훈련 라벨:\",  train_labels.shape)\n",
        "print(\"테스트 이미지 : \", test_images.shape)\n",
        "print(\"테스트 라벨 : \", test_labels.shape)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "mnist_idx = 100\n",
        "\n",
        "\n",
        "print('[label]')\n",
        "print('number label = ', train_labels[mnist_idx])\n",
        "print('\\n')\n",
        "\n",
        "print('[image]')\n",
        "\n",
        "for row in train_images[mnist_idx]:\n",
        "    for col in row:\n",
        "        print(\"%10f\" % col, end=\"\")\n",
        "    print('\\n')\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "image = train_images[mnist_idx]\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i4_braUpTV1I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#주가 데이터 읽어오기\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph() # 중요한 부분이다; 이것이 없으면 런타임을 항상 리셋 해 주어야 한다.\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 한국거래소에서 종목코드 가져오기\n",
        "code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]\n",
        "\n",
        "# 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌 \n",
        "code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)\n",
        "\n",
        "# 우리가 필요한 것은 회사명과 종목코드이기 때문에 필요없는 column들은 제외해준다. \n",
        "code_df = code_df[['회사명', '종목코드']]\n",
        "\n",
        "# 한글로된 컬럼명을 영어로 바꿔준다. \n",
        "code_df = code_df.rename(columns={'회사명': 'name', '종목코드': 'code'}) \n",
        "code_df.head()\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 종목 이름을 입력하면 종목에 해당하는 코드를 불러와 \n",
        "# 네이버 금융(http://finance.naver.com)에 넣어줌 \n",
        "def get_url(item_name, code_df): \n",
        "    code = code_df.query(\"name=='{}'\".format(item_name))['code'].to_string(index=False) \n",
        "    url = 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code=code) \n",
        "    print(\"요청 URL = {}\".format(url)) \n",
        "    return url\n",
        "\n",
        "# 신라젠의 일자데이터 url 가져오기 \n",
        "item_name='신라젠' \n",
        "url = get_url(item_name, code_df) \n",
        "print(url)\n",
        "\n",
        "# 일자 데이터를 담을 df라는 DataFrame 정의 \n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "# 1페이지에서 20페이지의 데이터만 가져오기 \n",
        "for page in range(1, 21): \n",
        "    pg_url = '{url}&page={page}'.format(url=url, page=page)\n",
        "    print(pg_url)\n",
        "#    df = pd.read_html(pg_url)\n",
        "    df = df.append(pd.read_html(pg_url, header=0)[0], ignore_index=True)\n",
        " \n",
        "\n",
        "\n",
        "# 한글로 된 컬럼명을 영어로 바꿔줌 \n",
        "df = df.rename(columns= {'날짜': 'date', '종가': 'close', '전일비': 'diff', '시가': 'open', '고가': 'high', '저가': 'low', '거래량': 'volume'}) \n",
        "\n",
        "# 데이터의 타입을 int형으로 바꿔줌 \n",
        "#df[['close', 'diff', 'open', 'high', 'low', 'volume']]  = df[['close', 'diff', 'open', 'high', 'low', 'volume']].astype(int) \n",
        "\n",
        "# 일자(date)를 기준으로 오름차순 정렬 \n",
        "df = df.sort_values(by=['date'], ascending=True) \n",
        "\n",
        "# 상위 5개 데이터 확인\n",
        "print( df.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xih8ITk5raxI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd #pandas만 호출하면 된다. 다른 함수는 호출할 필요 없다.\n",
        "\n",
        "df=pd.read_html('https://coinmarketcap.com/currencies/bitcoin/historical-data/?start=20130428&end=20180116', flavor='html5lib') \n",
        "df = df[0]\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1bePrspVuyy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Nov  9 11:09:39 2018\n",
        "\n",
        "@author: user\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph() # 중요한 부분이다; 이것이 없으면 런타임을 항상 리셋 해 주어야 한다.\n",
        "\n",
        "\n",
        "code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]\n",
        "\n",
        "# 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌 \n",
        "code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)\n",
        "\n",
        "# 우리가 필요한 것은 회사명과 종목코드이기 때문에 필요없는 column들은 제외해준다. \n",
        "code_df = code_df[['회사명', '종목코드']]\n",
        "\n",
        "# 한글로된 컬럼명을 영어로 바꿔준다. \n",
        "code_df = code_df.rename(columns={'회사명': 'name', '종목코드': 'code'}) \n",
        "code_df.head()\n",
        "\n",
        "# 종목 이름을 입력하면 종목에 해당하는 코드를 불러와 \n",
        "# 네이버 금융(http://finance.naver.com)에 넣어줌 \n",
        "def get_url(item_name, code_df): \n",
        "    code = code_df.query(\"name=='{}'\".format(item_name))['code'].to_string(index=False) \n",
        "    url = 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code=code) \n",
        "    print(\"요청 URL = {}\".format(url)) \n",
        "    return url\n",
        "\n",
        "# 신라젠의 일자데이터 url 가져오기 \n",
        "item_name='신라젠' \n",
        "url = get_url(item_name, code_df) \n",
        "print(url)\n",
        "\n",
        "# 일자 데이터를 담을 df라는 DataFrame 정의 \n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "# 1페이지에서 20페이지의 데이터만 가져오기 \n",
        "for page in range(1, 21): \n",
        "    pg_url = \"{url}&page={page}\".format(url=url, page=page) \n",
        "    df = df.append(pd.read_html(pg_url, header=0)[0], ignore_index=True)\n",
        "\n",
        "# df.dropna()를 이용해 결측값 있는 행 제거 \n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "print( df.head() )\n",
        "\n",
        "\n",
        "# 한글로 된 컬럼명을 영어로 바꿔줌 \n",
        "df = df.rename(columns= {'날짜': 'date', '종가': 'close', '전일비': 'diff', \n",
        "                         '시가': 'open', '고가': 'high', '저가': 'low', '거래량': 'volume'})\n",
        "\n",
        "# 데이터의 타입을 int형으로 바꿔줌 \n",
        "df[['close', 'diff', 'open', 'high', 'low', 'volume']] = df[['close', 'diff', 'open', 'high', 'low', 'volume']].astype(int)\n",
        "\n",
        "# 컬럼명 'date'의 타입을 date로 바꿔줌 \n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# 일자(date)를 기준으로 오름차순 정렬 \n",
        "df = df.sort_values(by=['date'], ascending=True) \n",
        "\n",
        "# 상위 5개 데이터 확인\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIG2v9V-B48i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import time\n",
        " \n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "  \n",
        "stockItem = '005930'\n",
        " \n",
        "url = 'http://finance.naver.com/item/sise_day.nhn?code='+ stockItem\n",
        "html = urlopen(url) \n",
        "source = BeautifulSoup(html.read(), \"html.parser\")\n",
        " \n",
        "maxPage=source.find_all(\"table\",align=\"center\")\n",
        "mp = maxPage[0].find_all(\"td\",class_=\"pgRR\")\n",
        "mpNum = int(mp[0].a.get('href')[-3:])\n",
        "                                            \n",
        "for page in range(1, mpNum+1):\n",
        "  print (str(page) )\n",
        "  url = 'http://finance.naver.com/item/sise_day.nhn?code=' + stockItem +'&page='+ str(page)\n",
        "  html = urlopen(url)\n",
        "  source = BeautifulSoup(html.read(), \"html.parser\")\n",
        "  srlists=source.find_all(\"tr\")\n",
        "  isCheckNone = None\n",
        "   \n",
        "  if((page % 1) == 0):\n",
        "    time.sleep(1.50)\n",
        " \n",
        "  for i in range(1,len(srlists)-1):\n",
        "   if(srlists[i].span != isCheckNone):\n",
        "     \n",
        "    srlists[i].td.text\n",
        "    print(srlists[i].find_all(\"td\",align=\"center\")[0].text, srlists[i].find_all(\"td\",class_=\"num\")[0].text )\n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n96977FwR4wE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 주가 데이터 읽어오기 ...; 간단한 방식\n",
        "# 참조 : https://pandas-datareader.readthedocs.io/en/latest/remote_data.html#remote-data-google\n",
        "\n",
        "from pandas_datareader import data\n",
        "import datetime\n",
        "import fix_yahoo_finance as yf\n",
        "yf.pdr_override() \n",
        "\n",
        "symbol = '035420.KS'\n",
        "#symbol = \"KRX:KOSPI\" \n",
        "data_source='yahoo' # 'google'는 동작하지않음; 'yahoo'는 동작\n",
        "#start_date = '2018-01-01'\n",
        "#end_date = '2019-01-01'\n",
        "start = datetime.datetime(2010, 1, 1)\n",
        "end   = datetime.datetime(2013, 1, 27)\n",
        "\n",
        "#df = data.DataReader(symbol, data_source,start_date, end_date)\n",
        "df = data.get_data_yahoo(symbol, start, end)\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wyq8-fDOdIbr",
        "colab_type": "code",
        "outputId": "a2024b52-d396-406b-aacd-0b0b0ab26fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import html5lib\n",
        "\n",
        "stockItem = '005930'\n",
        "\n",
        "url = 'http://finance.naver.com/item/sise_day.nhn?code=' + '005930'\n",
        "\n",
        "dfs = pd.read_html(url)\n",
        "\n",
        "df = dfs[0]\n",
        "\n",
        "print(df.index)\n",
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RangeIndex(start=0, stop=15, step=1)\n",
            "Index(['날짜', '종가', '전일비', '시가', '고가', '저가', '거래량'], dtype='object')\n",
            "           날짜       종가    전일비       시가       고가       저가         거래량\n",
            "0         NaN      NaN    NaN      NaN      NaN      NaN         NaN\n",
            "1  2019.04.26  44850.0  200.0  44200.0  45000.0  43800.0   9367544.0\n",
            "2  2019.04.25  44650.0  100.0  44250.0  45000.0  44100.0  10868965.0\n",
            "3  2019.04.24  44750.0  450.0  45400.0  45650.0  44150.0  13299267.0\n",
            "4  2019.04.23  45200.0  150.0  45050.0  45500.0  45000.0   6920566.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GnkAcBriaFwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Apr 25 21:02:39 2019\n",
        "\n",
        "@author: Home\n",
        "\"\"\"\n",
        "#주가 데이터 읽어오기\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph() # 중요한 부분이다; 이것이 없으면 런타임을 항상 리셋 해 주어야 한다.\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 한국거래소에서 종목코드 가져오기\n",
        "code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]\n",
        "\n",
        "# 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌 \n",
        "code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)\n",
        "\n",
        "# 우리가 필요한 것은 회사명과 종목코드이기 때문에 필요없는 column들은 제외해준다. \n",
        "code_df = code_df[['회사명', '종목코드']]\n",
        "\n",
        "# 한글로된 컬럼명을 영어로 바꿔준다. \n",
        "code_df = code_df.rename(columns={'회사명': 'name', '종목코드': 'code'}) \n",
        "code_df.head()\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 종목 이름을 입력하면 종목에 해당하는 코드를 불러와 \n",
        "# 네이버 금융(http://finance.naver.com)에 넣어줌 \n",
        "def get_url(item_name, code_df): \n",
        "    code = code_df.query(\"name=='{}'\".format(item_name))['code'].to_string(index=False) \n",
        "    url = 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code=code) \n",
        "    print(\"요청 URL = {}\".format(url)) \n",
        "    return url\n",
        "\n",
        "# 신라젠의 일자데이터 url 가져오기 \n",
        "item_name='신라젠' \n",
        "url = get_url(item_name, code_df) \n",
        "print(url)\n",
        "\n",
        "# 일자 데이터를 담을 df라는 DataFrame 정의 \n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "# 1페이지에서 20페이지의 데이터만 가져오기 \n",
        "for page in range(1, 21): \n",
        "    pg_url = '{url}&page={page}'.format(url=url, page=page)\n",
        "    print(pg_url)\n",
        "    df = df.append(pd.read_html(pg_url, header=0)[0], ignore_index=True)\n",
        " \n",
        "#df.head()\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# 한글로 된 컬럼명을 영어로 바꿔줌 \n",
        "df = df.rename(columns= {'날짜': 'date', '종가': 'close', '전일비': 'diff', '시가': 'open', '고가': 'high', '저가': 'low', '거래량': 'volume'}) \n",
        "\n",
        "# 데이터의 타입을 int형으로 바꿔줌 \n",
        "#df[['close', 'diff', 'open', 'high', 'low', 'volume']]  = df[['close', 'diff', 'open', 'high', 'low', 'volume']].astype(int) \n",
        "\n",
        "# 일자(date)를 기준으로 오름차순 정렬 \n",
        "df = df.sort_values(by=['date'], ascending=True) \n",
        "\n",
        "# 상위 5개 데이터 확인\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}